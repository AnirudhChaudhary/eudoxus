<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synthetic Programming Elicitation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #F7F7F7;
            color: #001011;
        }
        header {
            padding: 0.5rem 0;
            padding-top: 2rem;
            text-align: center;
            max-width: 600px;
            margin: 0 auto;
            line-height: 1.2;
            font-weight: 700;
            font-size: large;
        }
        main {
            max-width: 600px;
            margin: 0rem auto;
            background: #F7F7F7;
        }
        section {
            margin-bottom: 1.5rem;
        }
        h1, h2 {
            color: #001011;
        }
        a {
            color: #3AAFB9;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        blockquote {
            margin: 1.5rem 0;
            padding: 1rem;
            background-color: #f0f0f0;
            border-left: 5px solid #3AAFB9;
            font-style: italic;
            color: #333;
        }
        blockquote em {
            font-weight: bold;
            color: #001011;
        }
    </style>
</head>
<body>
    <header>
        <h1>Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages</h1>
    </header>
    <main>
        <section>
            <p>This is the supplementary material for <a href="https://arxiv.org/abs/2406.03636">Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages</a>. For the code and installation instructions, please see <a href="https://github.com/FedericoAureliano/eudoxus">the GitHub repository</a>.</p>
            <blockquote>
                Recent advances in large language models (LLMs) for code applications have demonstrated remarkable zero-shot fluency and instruction following on challenging code related tasks ranging from test case generation to self-repair. Unsurprisingly, however, models struggle to compose syntactically valid programs in programming languages unrepresented in pre-training, referred to as very low-resource Programming Languages (VLPLs). VLPLs appear in crucial settings, including domain-specific languages for internal tools, tool-chains for legacy languages, and formal verification frameworks. Inspired by an HCI technique called natural program elicitation, we propose designing an intermediate language that LLMs "naturally" know how to use and which can be automatically compiled to a target VLPL. When LLMs generate code that lies outside of this intermediate language, we use compiler techniques to repair the code into programs in the intermediate language. Overall, we introduce <em>synthetic programming elicitation and compilation</em> (SPEAC), an approach that enables LLMs to generate syntactically valid code even for VLPLs. We empirically evaluate the performance of SPEAC in a case study for the UCLID5 formal verification language and find that, compared to existing retrieval and fine-tuning baselines, SPEAC produces syntactically correct programs more frequently and without sacrificing semantic correctness.
            </blockquote>
        </section>
        <section>
            <h2>Data</h2>
            <p>Please find the challenge problems in the <a href="https://github.com/FedericoAureliano/eudoxus/tree/main/docs/data">docs/data</a> folder of the GitHub repository. Please find the raw outputs of our experiments in the <a href="https://github.com/FedericoAureliano/eudoxus/tree/main/docs/results">docs/results</a> folder of the GitHub repository.</p>
            <p>For example, consider the problem <a href="https://github.com/FedericoAureliano/eudoxus/tree/main/docs/data/LeeSeshia/ls-ex3_13.txt">Lee Seshia Ex. 3-13</a>. The model generated by our approach using GPT-3.5-turbo is <a href="https://github.com/FedericoAureliano/eudoxus/tree/main/docs/results/eudoxus-gpt35/ls-ex3_13.ucl">here</a> and the full interaction with the LLM that produced this output is <a href="https://github.com/FedericoAureliano/eudoxus/tree/main/docs/results/eudoxus-gpt35/ls-ex3_13.txt">here</a>. We graded this output <a href="https://github.com/FedericoAureliano/eudoxus/blob/main/docs/results/correctness.csv">4/5</a> because it is almost perfectly correct. One small mistake is that it declares the pedestrian input signal as a local variable.</p>
        </section>
    </main>
</body>
</html>
